<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修Pipe——高性能IO(一)' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>Pipe——高性能IO(一)</center></div><div class='banquan'>原文出处:本文由博客园博主yswenli提供。<br/>
原文连接:https://www.cnblogs.com/yswenli/p/11810317.html</div><br>
    <p><code>System.IO.Pipelines</code>是一个新的库，旨在简化在.NET中执行高性能IO的过程。它是一个依赖.NET Standard的库，<strong>适用于所有.NET实现</strong>。</p>
<p>Pipelines诞生于.NET Core团队，为使Kestrel成为业界最快的Web服务器之一。最初从作为Kestrel内部的实现细节发展成为可重用的API，它在.Net Core 2.1中作为可用于所有.NET开发人员的最高级BCL API（System.IO.Pipelines）提供。</p>
<h2 id="它解决了什么问题">它解决了什么问题？</h2>
<p>为了正确解析Stream或Socket中的数据，代码有固定的样板，并且有许多极端情况，为了处理他们，不得不编写难以维护的复杂代码。<br />实现高性能和正确性，同时也难以处理这种复杂性。Pipelines旨在解决这种复杂性。</p>
<h2 id="有多复杂">有多复杂？</h2>
<p>让我们从一个简单的问题开始吧。我们想编写一个TCP服务器，它接收来自客户端的用行分隔的消息（由<code>\n</code>分隔）。（译者注：即一行为一条消息）</p>
<h2 id="使用networkstream的tcp服务器">使用NetworkStream的TCP服务器</h2>
<p>在Pipelines之前用.NET编写的典型代码如下所示：</p>
<pre><code><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">async Task <span class="hljs-title">ProcessLinesAsync(<span class="hljs-params">NetworkStream stream)
{
    <span class="hljs-keyword">var buffer = <span class="hljs-keyword">new <span class="hljs-keyword">byte[<span class="hljs-number">1024];
    <span class="hljs-keyword">await stream.ReadAsync(buffer, <span class="hljs-number">0, buffer.Length);
    
    <span class="hljs-comment">// 在buffer中处理一行消息
    ProcessLine(buffer);
}</span></span></span></span></span></span></span></span></span></span></span></code></pre>
<p>此代码可能在本地测试时正确工作，但它有几个潜在错误：</p>
<ul>
<li>一次<code>ReadAsync</code>调用可能没有收到整个消息（行尾）。</li>
<li>它忽略了<code>stream.ReadAsync()</code>返回值中实际填充到<code>buffer</code>中的数据量。（译者注：即不一定将<code>buffer</code>填充满）</li>
<li>一次<code>ReadAsync</code>调用不能处理多条消息。</li>
</ul>
<p>这些是读取流数据时常见的一些缺陷。为了解决这个问题，我们需要做一些改变：</p>
<ul>
<li>我们需要缓冲传入的数据，直到找到新的行。</li>
<li>我们需要解析缓冲区中返回的所有行</li>
</ul>
<pre><code><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">async Task <span class="hljs-title">ProcessLinesAsync(<span class="hljs-params">NetworkStream stream)
{
    <span class="hljs-keyword">var buffer = <span class="hljs-keyword">new <span class="hljs-keyword">byte[<span class="hljs-number">1024];
    <span class="hljs-keyword">var bytesBuffered = <span class="hljs-number">0;
    <span class="hljs-keyword">var bytesConsumed = <span class="hljs-number">0;

    <span class="hljs-keyword">while (<span class="hljs-literal">true)
    {
        <span class="hljs-keyword">var bytesRead = <span class="hljs-keyword">await stream.ReadAsync(buffer, bytesBuffered, buffer.Length - bytesBuffered);
        <span class="hljs-keyword">if (bytesRead == <span class="hljs-number">0)
        {
            <span class="hljs-comment">// EOF 已经到末尾
            <span class="hljs-keyword">break;
        }
        <span class="hljs-comment">// 跟踪已缓冲的字节数
        bytesBuffered += bytesRead;
        
        <span class="hljs-keyword">var linePosition = <span class="hljs-number">-1;

        <span class="hljs-keyword">do
        {
            <span class="hljs-comment">// 在缓冲数据中查找找一个行末尾
            linePosition = Array.IndexOf(buffer, (<span class="hljs-keyword">byte)&lsquo;\n&lsquo;, bytesConsumed, bytesBuffered - bytesConsumed);

            <span class="hljs-keyword">if (linePosition &gt;= <span class="hljs-number">0)
            {
                <span class="hljs-comment">// 根据偏移量计算一行的长度
                <span class="hljs-keyword">var lineLength = linePosition - bytesConsumed;

                <span class="hljs-comment">// 处理这一行
                ProcessLine(buffer, bytesConsumed, lineLength);

                <span class="hljs-comment">// 移动bytesConsumed为了跳过我们已经处理掉的行 (包括\n)
                bytesConsumed += lineLength + <span class="hljs-number">1;
            }
        }
        <span class="hljs-keyword">while (linePosition &gt;= <span class="hljs-number">0);
    }
}</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></code></pre>
<p>这一次，这可能适用于本地开发，但一行可能大于1KiB（1024字节）。我们需要调整输入缓冲区的大小，直到找到新行。</p>
<p>因此，我们可以在堆上分配缓冲区去处理更长的一行。我们从客户端解析较长的一行时，可以通过使用<code>ArrayPool&lt;byte&gt;</code>避免重复分配缓冲区来改进这一点。</p>
<pre><code><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">async Task <span class="hljs-title">ProcessLinesAsync(<span class="hljs-params">NetworkStream stream)
{
    <span class="hljs-keyword">byte[] buffer = ArrayPool&lt;<span class="hljs-keyword">byte&gt;.Shared.Rent(<span class="hljs-number">1024);
    <span class="hljs-keyword">var bytesBuffered = <span class="hljs-number">0;
    <span class="hljs-keyword">var bytesConsumed = <span class="hljs-number">0;

    <span class="hljs-keyword">while (<span class="hljs-literal">true)
    {
        <span class="hljs-comment">// 在buffer中计算中剩余的字节数
        <span class="hljs-keyword">var bytesRemaining = buffer.Length - bytesBuffered;

        <span class="hljs-keyword">if (bytesRemaining == <span class="hljs-number">0)
        {
            <span class="hljs-comment">// 将buffer size翻倍 并且将之前缓冲的数据复制到新的缓冲区
            <span class="hljs-keyword">var newBuffer = ArrayPool&lt;<span class="hljs-keyword">byte&gt;.Shared.Rent(buffer.Length * <span class="hljs-number">2);
            Buffer.BlockCopy(buffer, <span class="hljs-number">0, newBuffer, <span class="hljs-number">0, buffer.Length);
            <span class="hljs-comment">// 将旧的buffer丢回池中
            ArrayPool&lt;<span class="hljs-keyword">byte&gt;.Shared.Return(buffer);
            buffer = newBuffer;
            bytesRemaining = buffer.Length - bytesBuffered;
        }

        <span class="hljs-keyword">var bytesRead = <span class="hljs-keyword">await stream.ReadAsync(buffer, bytesBuffered, bytesRemaining);
        <span class="hljs-keyword">if (bytesRead == <span class="hljs-number">0)
        {
            <span class="hljs-comment">// EOF 末尾
            <span class="hljs-keyword">break;
        }
        
        <span class="hljs-comment">// 跟踪已缓冲的字节数
        bytesBuffered += bytesRead;
        
        <span class="hljs-keyword">do
        {
            <span class="hljs-comment">// 在缓冲数据中查找找一个行末尾
            linePosition = Array.IndexOf(buffer, (<span class="hljs-keyword">byte)&lsquo;\n&lsquo;, bytesConsumed, bytesBuffered - bytesConsumed);

            <span class="hljs-keyword">if (linePosition &gt;= <span class="hljs-number">0)
            {
                <span class="hljs-comment">// 根据偏移量计算一行的长度
                <span class="hljs-keyword">var lineLength = linePosition - bytesConsumed;

                <span class="hljs-comment">// 处理这一行
                ProcessLine(buffer, bytesConsumed, lineLength);

                <span class="hljs-comment">// 移动bytesConsumed为了跳过我们已经处理掉的行 (包括\n)
                bytesConsumed += lineLength + <span class="hljs-number">1;
            }
        }
        <span class="hljs-keyword">while (linePosition &gt;= <span class="hljs-number">0);
    }
}</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></code></pre>
<p>这段代码有效，但现在我们正在重新调整缓冲区大小，从而产生更多缓冲区副本。它将使用更多内存，因为根据代码在处理一行行后不会缩缓冲区的大小。为避免这种情况，我们可以存储缓冲区序列，而不是每次超过1KiB大小时调整大小。</p>
<p>此外，我们不会增长1KiB的 缓冲区，直到它完全为空。这意味着我们最终传递给<code>ReadAsync</code>越来越小的缓冲区，这将导致对操作系统的更多调用。</p>
<p>为了缓解这种情况，我们将在现有缓冲区中剩余少于512个字节时分配一个新缓冲区：<span style="font-style: italic; background-color: initial; color: #333333;"><br /></span></p>
<pre><code><code class="hljs cs"><span class="hljs-keyword">public <span class="hljs-keyword">class <span class="hljs-title">BufferSegment
{
    <span class="hljs-keyword">public <span class="hljs-keyword">byte[] Buffer { <span class="hljs-keyword">get; <span class="hljs-keyword">set; }
    <span class="hljs-keyword">public <span class="hljs-keyword">int Count { <span class="hljs-keyword">get; <span class="hljs-keyword">set; }

    <span class="hljs-keyword">public <span class="hljs-keyword">int Remaining =&gt; Buffer.Length - Count;
}

<span class="hljs-function"><span class="hljs-keyword">async Task <span class="hljs-title">ProcessLinesAsync(<span class="hljs-params">NetworkStream stream)
{
    <span class="hljs-keyword">const <span class="hljs-keyword">int minimumBufferSize = <span class="hljs-number">512;

    <span class="hljs-keyword">var segments = <span class="hljs-keyword">new List&lt;BufferSegment&gt;();
    <span class="hljs-keyword">var bytesConsumed = <span class="hljs-number">0;
    <span class="hljs-keyword">var bytesConsumedBufferIndex = <span class="hljs-number">0;
    <span class="hljs-keyword">var segment = <span class="hljs-keyword">new BufferSegment { Buffer = ArrayPool&lt;<span class="hljs-keyword">byte&gt;.Shared.Rent(<span class="hljs-number">1024) };

    segments.Add(segment);

    <span class="hljs-keyword">while (<span class="hljs-literal">true)
    {
        <span class="hljs-comment">// Calculate the amount of bytes remaining in the buffer
        <span class="hljs-keyword">if (segment.Remaining &lt; minimumBufferSize)
        {
            <span class="hljs-comment">// Allocate a new segment
            segment = <span class="hljs-keyword">new BufferSegment { Buffer = ArrayPool&lt;<span class="hljs-keyword">byte&gt;.Shared.Rent(<span class="hljs-number">1024) };
            segments.Add(segment);
        }

        <span class="hljs-keyword">var bytesRead = <span class="hljs-keyword">await stream.ReadAsync(segment.Buffer, segment.Count, segment.Remaining);
        <span class="hljs-keyword">if (bytesRead == <span class="hljs-number">0)
        {
            <span class="hljs-keyword">break;
        }

        <span class="hljs-comment">// Keep track of the amount of buffered bytes
        segment.Count += bytesRead;

        <span class="hljs-keyword">while (<span class="hljs-literal">true)
        {
            <span class="hljs-comment">// Look for a EOL in the list of segments
            <span class="hljs-keyword">var (segmentIndex, segmentOffset) = IndexOf(segments, (<span class="hljs-keyword">byte)&lsquo;\n&lsquo;, bytesConsumedBufferIndex, bytesConsumed);

            <span class="hljs-keyword">if (segmentIndex &gt;= <span class="hljs-number">0)
            {
                <span class="hljs-comment">// Process the line
                ProcessLine(segments, segmentIndex, segmentOffset);

                bytesConsumedBufferIndex = segmentOffset;
                bytesConsumed = segmentOffset + <span class="hljs-number">1;
            }
            <span class="hljs-keyword">else
            {
                <span class="hljs-keyword">break;
            }
        }

        <span class="hljs-comment">// Drop fully consumed segments from the list so we don&lsquo;t look at them again
        <span class="hljs-keyword">for (<span class="hljs-keyword">var i = bytesConsumedBufferIndex; i &gt;= <span class="hljs-number">0; --i)
        {
            <span class="hljs-keyword">var consumedSegment = segments[i];
            <span class="hljs-comment">// Return all segments unless this is the current segment
            <span class="hljs-keyword">if (consumedSegment != segment)
            {
                ArrayPool&lt;<span class="hljs-keyword">byte&gt;.Shared.Return(consumedSegment.Buffer);
                segments.RemoveAt(i);
            }
        }
    }
}

(<span class="hljs-keyword">int segmentIndex, <span class="hljs-keyword">int segmentOffest) IndexOf(List&lt;BufferSegment&gt; segments, <span class="hljs-keyword">byte <span class="hljs-keyword">value, <span class="hljs-keyword">int startBufferIndex, <span class="hljs-keyword">int startSegmentOffset)
{
    <span class="hljs-keyword">var first = <span class="hljs-literal">true;
    <span class="hljs-keyword">for (<span class="hljs-keyword">var i = startBufferIndex; i &lt; segments.Count; ++i)
    {
        <span class="hljs-keyword">var segment = segments[i];
        <span class="hljs-comment">// Start from the correct offset
        <span class="hljs-keyword">var offset = first ? startSegmentOffset : <span class="hljs-number">0;
        <span class="hljs-keyword">var index = Array.IndexOf(segment.Buffer, <span class="hljs-keyword">value, offset, segment.Count - offset);

        <span class="hljs-keyword">if (index &gt;= <span class="hljs-number">0)
        {
            <span class="hljs-comment">// Return the buffer index and the index within that segment where EOL was found
            <span class="hljs-keyword">return (i, index);
        }

        first = <span class="hljs-literal">false;
    }
    <span class="hljs-keyword">return (<span class="hljs-number">-1, <span class="hljs-number">-1);
}</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></code></pre>
<p>此代码只是得到很多更加复杂。当我们正在寻找分隔符时，我们同时跟踪已填充的缓冲区序列。为此，我们此处使用<code>List&lt;BufferSegment&gt;</code>查找新行分隔符时表示缓冲数据。其结果是，<code>ProcessLine</code>和<code>IndexOf</code>现在接受<code>List&lt;BufferSegment&gt;</code>作为参数，而不是一个<code>byte[]，offset和count</code>。我们的解析逻辑现在需要处理一个或多个缓冲区序列。</p>
<p>我们的服务器现在处理部分消息，它使用池化内存来减少总体内存消耗，但我们还需要进行更多更改：</p>
<ol>
<li>我们使用的<code>byte[]</code>和<code>ArrayPool&lt;byte&gt;</code>的只是普通的托管数组。这意味着无论何时我们执行<code>ReadAsync</code>或<code>WriteAsync</code>，这些缓冲区都会在异步操作的生命周期内被固定（以便与操作系统上的本机IO API互操作）。这对GC有性能影响，因为无法移动固定内存，这可能导致堆碎片。根据异步操作挂起的时间长短，池的实现可能需要更改。</li>
<li>可以通过解耦<strong>读取逻辑</strong>和<strong>处理逻辑</strong>来优化吞吐量。这会创建一个批处理效果，使解析逻辑可以使用更大的缓冲区块，而不是仅在解析单个行后才读取更多数据。这引入了一些额外的复杂性
<ul>
<li>我们需要两个彼此独立运行的循环。一个读取Socket和一个解析缓冲区。</li>
<li>当数据可用时，我们需要一种方法来向<strong>解析逻辑</strong>发出信号。</li>
<li>我们需要决定如果循环读取Socket&ldquo;太快&rdquo;会发生什么。如果<strong>解析逻辑</strong>无法跟上，我们需要一种方法来限制<strong>读取循环（逻辑）</strong>。这通常被称为&ldquo;流量控制&rdquo;或&ldquo;背压&rdquo;。</li>
<li>我们需要确保事情是线程安全的。我们现在在<strong>读取循环</strong>和<strong>解析循环</strong>之间共享多个缓冲区，并且这些缓冲区在不同的线程上独立运行。</li>
<li><strong>内存管理逻辑</strong>现在分布在两个不同的代码段中，从填充缓冲区池的代码是从套接字读取的，而从缓冲区池取数据的代码是<strong>解析逻辑</strong>。</li>
<li>我们需要非常小心在<strong>解析逻辑</strong>完成之后我们如何处理缓冲区序列。如果我们不小心，我们可能会返回一个仍由Socket读取逻辑写入的缓冲区序列。</li>
</ul>
</li>
</ol>
<p>复杂性已经到了极端（我们甚至没有涵盖所有案例）。高性能网络应用通常意味着编写非常复杂的代码，以便从系统中获得更高的性能。</p>
<p><strong>System.IO.Pipelines的目标是使这种类型的代码更容易编写。</strong></p>
<h2 id="使用system.io.pipelines的tcp服务器">使用System.IO.Pipelines的TCP服务器</h2>
<p>让我们来看看这个例子的样子System.IO.Pipelines：</p>
<pre><code><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">async Task <span class="hljs-title">ProcessLinesAsync(<span class="hljs-params">Socket socket)
{
    <span class="hljs-keyword">var pipe = <span class="hljs-keyword">new Pipe();
    Task writing = FillPipeAsync(socket, pipe.Writer);
    Task reading = ReadPipeAsync(pipe.Reader);

    <span class="hljs-keyword">return Task.WhenAll(reading, writing);
}

<span class="hljs-function"><span class="hljs-keyword">async Task <span class="hljs-title">FillPipeAsync(<span class="hljs-params">Socket socket, PipeWriter writer)
{
    <span class="hljs-keyword">const <span class="hljs-keyword">int minimumBufferSize = <span class="hljs-number">512;

    <span class="hljs-keyword">while (<span class="hljs-literal">true)
    {
        <span class="hljs-comment">// 从PipeWriter至少分配512字节
        Memory&lt;<span class="hljs-keyword">byte&gt; memory = writer.GetMemory(minimumBufferSize);
        <span class="hljs-keyword">try 
        {
            <span class="hljs-keyword">int bytesRead = <span class="hljs-keyword">await socket.ReceiveAsync(memory, SocketFlags.None);
            <span class="hljs-keyword">if (bytesRead == <span class="hljs-number">0)
            {
                <span class="hljs-keyword">break;
            }
            <span class="hljs-comment">// 告诉PipeWriter从套接字读取了多少
            writer.Advance(bytesRead);
        }
        <span class="hljs-keyword">catch (Exception ex)
        {
            LogError(ex);
            <span class="hljs-keyword">break;
        }

        <span class="hljs-comment">// 标记数据可用，让PipeReader读取
        FlushResult result = <span class="hljs-keyword">await writer.FlushAsync();

        <span class="hljs-keyword">if (result.IsCompleted)
        {
            <span class="hljs-keyword">break;
        }
    }

    <span class="hljs-comment">// 告诉PipeReader没有更多的数据
    writer.Complete();
}

<span class="hljs-function"><span class="hljs-keyword">async Task <span class="hljs-title">ReadPipeAsync(<span class="hljs-params">PipeReader reader)
{
    <span class="hljs-keyword">while (<span class="hljs-literal">true)
    {
        ReadResult result = <span class="hljs-keyword">await reader.ReadAsync();

        ReadOnlySequence&lt;<span class="hljs-keyword">byte&gt; buffer = result.Buffer;
        SequencePosition? position = <span class="hljs-literal">null;

        <span class="hljs-keyword">do 
        {
            <span class="hljs-comment">// 在缓冲数据中查找找一个行末尾
            position = buffer.PositionOf((<span class="hljs-keyword">byte)&lsquo;\n&lsquo;);

            <span class="hljs-keyword">if (position != <span class="hljs-literal">null)
            {
                <span class="hljs-comment">// 处理这一行
                ProcessLine(buffer.Slice(<span class="hljs-number">0, position.Value));
                
                <span class="hljs-comment">// 跳过 这一行+\n (basically position 主要位置？)
                buffer = buffer.Slice(buffer.GetPosition(<span class="hljs-number">1, position.Value));
            }
        }
        <span class="hljs-keyword">while (position != <span class="hljs-literal">null);

        <span class="hljs-comment">// 告诉PipeReader我们以及处理多少缓冲
        reader.AdvanceTo(buffer.Start, buffer.End);

        <span class="hljs-comment">// 如果没有更多的数据，停止都去
        <span class="hljs-keyword">if (result.IsCompleted)
        {
            <span class="hljs-keyword">break;
        }
    }

    <span class="hljs-comment">// 将PipeReader标记为完成
    reader.Complete();
}</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></code></pre>
<p>我们的行读取器的pipelines版本有2个循环：</p>
<ul>
<li><code>FillPipeAsync</code>从Socket读取并写入PipeWriter。</li>
<li><code>ReadPipeAsync</code>从PipeReader中读取并解析传入的行。</li>
</ul>
<p>与原始示例不同，在任何地方都没有分配显式缓冲区。这是管道的核心功能之一。所有缓冲区管理都委托给PipeReader/PipeWriter实现。</p>
<p><strong>这使得使用代码更容易专注于业务逻辑而不是复杂的缓冲区管理。</strong></p>
<p>在第一个循环中，我们首先调用<code>PipeWriter.GetMemory(int)</code>从底层编写器获取一些内存; 然后我们调用<code>PipeWriter.Advance(int)</code>告诉PipeWriter我们实际写入缓冲区的数据量。然后我们调用<code>PipeWriter.FlushAsync()</code>来提供数据给PipeReader。</p>
<p>在第二个循环中，我们正在使用PipeWriter最终来自的缓冲区Socket。当调用<code>PipeReader.ReadAsync()</code>返回时，我们得到一个ReadResult包含2条重要信息，包括以<code>ReadOnlySequence&lt;byte&gt;</code>形式读取的数据和<code>bool IsCompleted</code>，让reader知道writer是否写完（EOF）。在找到行尾（EOL）分隔符并解析该行之后，我们将缓冲区切片以跳过我们已经处理过的内容，然后我们调用<code>PipeReader.AdvanceTo</code>告诉PipeReader我们消耗了多少数据。</p>
<p>在每个循环结束时，我们完成了reader和writer。这允许底层Pipe释放它分配的所有内存。</p>
<h2 id="system.io.pipelines">System.IO.Pipelines</h2>
<p>除了处理内存管理之外，其他核心管道功能还包括能够在Pipe不实际消耗数据的情况下查看数据。</p>
<p>PipeReader有两个核心API&nbsp;<code>ReadAsync</code>和<code>AdvanceTo</code>。<code>ReadAsync</code>获取Pipe数据，<code>AdvanceTo</code>告诉PipeReader不再需要这些缓冲区，以便可以丢弃它们（例如返回到底层缓冲池）。</p>
<hr />
<p>这是一个http解析器的示例，它在接收Pipe到有效起始行之前读取部分数据缓冲区数据。</p>
<p><img src="./images/Pipe——高性能IO(一)0.png" alt="技术分享图片" /></p>
<h2 id="readonlysequencet">ReadOnlySequence&lt;T&gt;</h2>
<p>该Pipe实现存储了在PipeWriter和PipeReader之间传递的缓冲区的链接列表。PipeReader.ReadAsync暴露一个ReadOnlySequence&lt;T&gt;新的BCL类型，它表示一个或多个ReadOnlyMemory&lt;T&gt;段的视图，类似于Span&lt;T&gt;和Memory&lt;T&gt;提供数组和字符串的视图。</p>
<p><img src="./images/Pipe——高性能IO(一)1.png" alt="技术分享图片" /></p>
<p>该Pipe内部维护指向reader和writer可以分配或更新它们的数据集合，。SequencePosition表示缓冲区链表中的单个点，可用于有效地对ReadOnlySequence&lt;T&gt;进行切片。</p>
<blockquote>
<p>这段实在翻译困难，给出原文<br />The Pipe internally maintains pointers to where the reader and writer are in the overall set of allocated data and updates them as data is written or read. The SequencePosition represents a single point in the linked list of buffers and can be used to efficiently slice the ReadOnlySequence</p>



</blockquote>
<p>由于ReadOnlySequence&lt;T&gt;可以支持一个或多个段，因此高性能处理逻辑通常基于单个或多个段来分割快速和慢速路径（fast and slow paths?）。</p>
<p>例如，这是一个将ASCII ReadOnlySequence&lt;byte&gt;转换为string以下内容的例程：</p>
<pre><code><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">string <span class="hljs-title">GetAsciiString(<span class="hljs-params">ReadOnlySequence&lt;<span class="hljs-keyword">byte&gt; buffer)
{
    <span class="hljs-keyword">if (buffer.IsSingleSegment)
    {
        <span class="hljs-keyword">return Encoding.ASCII.GetString(buffer.First.Span);
    }

    <span class="hljs-keyword">return <span class="hljs-keyword">string.Create((<span class="hljs-keyword">int)buffer.Length, buffer, (span, sequence) =&gt;
    {
        <span class="hljs-keyword">foreach (<span class="hljs-keyword">var segment <span class="hljs-keyword">in sequence)
        {
            Encoding.ASCII.GetChars(segment.Span, span);

            span = span.Slice(segment.Length);
        }
    });
}</span></span></span></span></span></span></span></span></span></span></span></span></span></code></pre>
<h2 id="背压和流量控制">背压和流量控制</h2>
<p>在一个完美的世界中，读取和解析工作是一个团队：读取线程消耗来自网络的数据并将其放入缓冲区，而解析线程负责构建适当的数据结构。通常，解析将比仅从网络复制数据块花费更多时间。结果，读取线程可以轻易地压倒解析线程。结果是读取线程必须减慢或分配更多内存来存储解析线程的数据。为获得最佳性能，在频繁暂停和分配更多内存之间存在平衡。</p>
<p>为了解决这个问题，管道有两个设置来控制数据的流量，PauseWriterThreshold和ResumeWriterThreshold。PauseWriterThreshold决定有多少数据应该在调用<code>PipeWriter.FlushAsync</code>之前进行缓冲停顿。ResumeWriterThreshold控制reader消耗多少后写入可以恢复。</p>
<p><img src="./images/Pipe——高性能IO(一)2.png" alt="技术分享图片" /></p>
<p>当Pipe的数据量超过PauseWriterThreshold，<code>PipeWriter.FlushAsync</code>会异步阻塞。数据量变得低于ResumeWriterThreshold，它会解锁时。两个值用于防止在极限附近发生反复阻塞和解锁。</p>
<h2 id="io调度">IO调度</h2>
<p>通常在使用async / await时，会在线程池线程或当前线程上调用continuation SynchronizationContext。</p>
<p>在执行IO时，对执行IO的位置进行细粒度控制非常重要，这样可以更有效地利用CPU缓存，这对于Web服务器等高性能应用程序至关重要。Pipelines公开了一个PipeScheduler确定异步回调运行位置的方法。这使得调用者可以精确控制用于IO的线程。</p>
<p>实践中的一个示例是在Kestrel Libuv传输中，其中IO回调在专用事件循环线程上运行。</p>
<h2 id="pipereader模式的其他好处">PipeReader模式的其他好处：</h2>
<ul>
<li>一些底层系统支持&ldquo;无缓冲等待&rdquo;，即，在底层系统中实际可用数据之前，永远不需要分配缓冲区。例如，在带有epoll的Linux上，可以等到数据准备好之后再实际提供缓冲区来进行读取。这避免了具有大量线程等待数据的问题不会立即需要保留大量内存。</li>
<li>默认情况下Pipe，可以轻松地针对网络代码编写单元测试，因为解析逻辑与网络代码分离，因此单元测试仅针对内存缓冲区运行解析逻辑，而不是直接从网络中消耗。它还可以轻松测试那些难以测试发送部分数据的模式。ASP.NET Core使用它来测试Kestrel的http解析器的各个方面。</li>
<li>允许将底层OS缓冲区（如Windows上的Registered IO API）暴露给用户代码的系统非常适合管道，因为缓冲区始终由PipeReader实现提供。</li>
</ul>
<h2 id="其他相关类型">其他相关类型</h2>
<p>作为制作System.IO.Pipelines的一部分，我们还添加了许多新的原始BCL类型：</p>
<ul>
<li><code>MemoryPool&lt;T&gt;</code>，<code>IMemoryOwner&lt;T&gt;</code>，<code>MemoryManager&lt;T&gt;</code>&nbsp;- .NET Core 1.0添加了<code>ArrayPool&lt;T&gt;</code>，在.NET Core 2.1中，我们现在有一个更通用的抽象，适用于任何工作的池<code>Memory&lt;T&gt;</code>。这提供了一个可扩展点，允许您插入更高级的分配策略以及控制缓冲区的管理方式（例如，提供预先固定的缓冲区而不是纯托管的阵列）。</li>
<li><code>IBufferWriter&lt;T&gt;</code>&nbsp;- 表示用于写入同步缓冲数据的接收器。（PipeWriter实现这个）</li>
<li>IValueTaskSource -&nbsp;<code>ValueTask&lt;T&gt;</code>自.NET Core 1.1以来就已存在，但在.NET Core 2.1中获得了一些超级权限，允许无分配的等待异步操作。有关详细信息，请参阅https://github.com/dotnet/corefx/issues/27445。</li>
</ul>
<h2 id="我如何使用管道">如何使用管道？</h2>
<p>API存在于<code>System.IO.Pipelines</code>&nbsp;nuget包中。</p>
<p>主要包含一个Pipe对象，它有一个Writer属性和Reader属性。</p>
<p>var pipe = new Pipe();<br />var writer = pipe.Writer;<br />var reader = pipe.Reader;&nbsp;</p>
<h3>Writer对象</h3>
<p>Writer对象用于从数据源读取数据，将数据写入管道中；它对应业务中的"读"操作。</p>
<p>var content = Encoding.Default.GetBytes("hello world");<br />var data    = new Memory&lt;byte&gt;(content);<br />var result  = await writer.WriteAsync(data);</p>
<p>另外，它也有一种使用Pipe申请Memory的方式</p>
<p>var buffer = writer.GetMemory(512);<br />content.CopyTo(buffer);<br />writer.Advance(content.Length);<br />var result = await writer.FlushAsync();&nbsp;</p>
<h3>Reader对象</h3>
<p>Reader对象用于从管道中获取数据源，它对应业务中的"用"操作。</p>
<p>首先获取管道的缓冲区：</p>
<p>var result = await reader.ReadAsync();<br />var buffer = result.Buffer;</p>
<p>这个Buffer是一个ReadOnlySequence&lt;byte&gt;对象，它是一个相当好的动态内存对象，并且相当高效。它本身由多段Memory&lt;byte&gt;组成，查看Memory段的方法有：</p>
<p>IsSingleSegment： 判断是否只有一段Memory&lt;byte&gt;<br />First： 获取第一段Memory&lt;byte&gt;<br />GetEnumerator: 获取分段的Memory&lt;byte&gt;<br />它从逻辑上也可以看成一段连续的Memory&lt;byte&gt;，也有类似的方法：</p>
<p>Length： 整个数据缓冲区长度<br />Slice： 分割缓冲区<br />CopyTo:　将内容复制到Span中<br />ToArray： 将内容复制到byte[]中<br />另外，它还有一个类似游标的位置对象SequencePosition，可以从其Position相关函数中使用，这里就不多介绍了。</p>
<p>这个缓冲区解决了"数据读不够"的问题，一次读取的不够下次可以接着读，不用缓冲区的动态分配，高效的内存管理方式带来了良好的性能，好用的接口是我们能更关注业务。</p>
<p>获取到缓冲区后，就是使用缓冲区的数据</p>
<p>var data = buffer.ToArray();</p>
<p>使用完后，告诉PIPE当前使用了多少数据，下次接着从结束位置后读起</p>
<p>reader.AdvanceTo(buffer.GetPosition(4));</p>
<p>这是一个相当实用的设计，它解决了"读了就得用"的问题，不仅可以将不用的数据下次再使用，还可以实现Peek的操作，只读但不改变游标。&nbsp;</p>
<h3>交互</h3>
<p>除了"读"和"用"操作外，它们之间还需要一些交互，例如：</p>
<p>读过程中数据源不可用，需要停止使用<br />使用过程中业务结束，需要中止数据源。<br />Reader和Writer都有一个Complete函数，用于通知结束：</p>
<p>reader.Complete();<br />writer.Complete();</p>
<p>在Writer写入和Reader读取时，会获得一个结果</p>
<p>FlushResult result = await writer.FlushAsync();<br />ReadResult result = await reader.ReadAsync();</p>
<p>它们都有一个IsComplete属性，可以根据它是否为true判断是否已经结束了读和写的操作。&nbsp;</p>
<h3>取消</h3>
<p>在写入和读取的时候，也可以传入一个CancellationToken，用于取消相应的操作。</p>
<p>writer.FlushAsync(CancellationToken.None);<br />reader.ReadAsync(CancellationToken.None);</p>
<p>如果取消成功，对应的Result的IsCanceled则为true</p>
<p>&nbsp;</p>
<blockquote>
<p><br />转载请标明本文来源：<a title="https://www.cnblogs.com/yswenli/p/11810317.html" href="https://www.cnblogs.com/yswenli/p/11810317.html" target="_blank">https://www.cnblogs.com/yswenli/p/11810317.html</a><br />更多内容欢迎Star、Fork我的的github：<a title="https://github.com/yswenli/" href="https://github.com/yswenli/" target="_blank">https://github.com/yswenli/</a><br />如果发现本文有什么问题和任何建议，也随时欢迎交流~</p>



</blockquote>
<pre class="hljs cs"><span class="hljs-keyword">&nbsp;</span></pre>
<p>&nbsp;</p>
</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>